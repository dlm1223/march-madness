---
title: "Pool Size Matters: Backtesting March Madness Strategies"
date: "March 3, 2017"
output: html_document
---

```{r setup, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

I made an [app](https://bracketmath.shinyapps.io/ncaa/) to optimize March Madness brackets. You can read more about it [here](https://github.com/dlm1223/march-madness/blob/master/README.md). For this post, I'm going to use the app to look at what size pool you should enter and also what parameters you should use in the app.


```{r , echo=F, eval=T , include=F}
wd<-getwd()
load("backtest results.Rda")
library(plyr);library(dplyr);library(ggplot2);library(ggrepel)

makePlot<-function(means, title="ROI by Optimization Percentile and numBrackets"){
  a<-ggplot(data=means, aes(fill=numBrackets, y=ROI, x=percentile)) +  
    geom_bar(position="dodge", stat="identity"    ,
             colour="black", # Use black outlines,
             size=.3) +      # Thinner lines
    geom_errorbar(aes(ymin = ROI - seROI, ymax = ROI + seROI),                
                  size=.3,    # Thinner lines
                  width=.2,
                  position=position_dodge(.9)) + 
    ylab("ROI (%)") +
    ggtitle(title)
  print(a)
}
groupedLine<-function(test, title="Cumulative Profit"){
  test[, c("percentile", "numBrackets")]<-sapply(test[, c("percentile", "numBrackets")], as.factor)
  
  a<-test%>% mutate(label = if_else(year == max(year), paste0(winningYears, "/8 Winning"), ifelse(year==min(year), numBrackets, NA_character_))) %>%
    ggplot( aes(x=year, y=CumProfit, group = numBrackets, colour = numBrackets)) +
    geom_line()+
    scale_colour_discrete(guide = 'none') +
    geom_label_repel(aes(label = label),
                     nudge_x = 1,
                     na.rm = TRUE)+
    ggtitle(title)
  print(a)
}
```

##Testing Parameter Combos:

I'm using 500 simulations-500 brackets for this and am testing it over 8 seasons, 2010-2017. I use the simulations and brackets to choose the optimal brackets and then I look at the profit and ROI using the actual results for the given year. **The first thing I do is look at performance of different parameter combos of the app.**


```{r fig1, echo=F, eval=T , include=T, fig.height = 3, fig.width = 5, fig.align = "center"}
backtest$numWinning<-rowSums(apply(backtest[, grepl("result", colnames(backtest))],2, function(x) x>=backtest$percentile  ), na.rm=T)
backtest$Prize<-(1/(1-backtest$percentile))*backtest$numWinning
backtest$Prize_same<-(1/(1-backtest$percentile))*(backtest$numWinning>=1)
backtest$Entry<-1*backtest$numBrackets


means<-ddply(backtest, .(percentile, numBrackets),
             summarize,ROI=100* sum(Prize_same-Entry)/sum(Entry), seROI=100*sd((Prize_same-Entry)/Entry)/length(year))
means[, c("percentile", "numBrackets")]<-sapply(means[, c("percentile", "numBrackets")], as.factor)
makePlot(means)

```

To get ROI above, I assume you entered $1/bracket and first place gets everything. So, for example percentile-99 means you are using .99 as the parameter and that the payout is $100 if the actual percentile was >=.99. So if I entered 1 bracket each year and won 20 dollars, my ROI=(20-8)/8*100=200%. Below I look more closely at the .90-parameter backtest:


```{r fig, echo=F, eval=T , include=T, fig.height = 3, fig.width = 5, fig.align = "center"}
backtest<-ddply(backtest, .(numBrackets, percentile),mutate,
                winningYears=sum(Prize_same>0),
                CumProfit=cumsum(Prize_same)-cumsum(Entry))
test<-backtest[backtest$percentile==.9,]
groupedLine(test, title="Cumulative Profit, 90th-percentile parameter")

```

As you can see in the above plots, the brackets from the 90th-percentile-parameter do best, and diversifying even has you winning in 7/8 years.

##Testing Payout Structures:

 **My next question is: is the better ROI for the 90th-percentile-parameter a function of the optimization algorithm or a function of the payout structure?** Meaning, is it doing better because it is giving you better brackets or because the payout structure is less top heavy? To test this hypothesis I use the same algorithm output but I re-calculate ROI using a medium-pool 20-man payout. Below I repeat the same pots, but calculate all payouts using the medium 20-man pool scoring as the scoring for all the parameters:


```{r fig2, echo=F, eval=T , include=T,fig.height = 3, fig.width = 5, fig.align = "center"}
percentile<-.95

backtest$numWinning<-rowSums(apply(backtest[, grepl("result", colnames(backtest))],2, function(x) x>=percentile  ), na.rm=T)
backtest$numSecond<-rowSums(apply(backtest[, grepl("result", colnames(backtest))],2, function(x) x<percentile & x>=percentile-(1-percentile) ), na.rm=T)
backtest$Prize<-(1/(1-percentile))*backtest$numWinning
backtest$Prize_same<-(1/(1-percentile))*(backtest$numWinning>=1)


means<-ddply(backtest, .(percentile, numBrackets), summarize,ROI=100*sum(Prize_same-Entry)/sum(Entry), seROI=100*sd((Prize_same-Entry)/Entry)/length(year))
means[, c("percentile", "numBrackets")]<-sapply(means[, c("percentile", "numBrackets")], as.factor)
makePlot(means, title="ROI, Medium Pool Scoring")

backtest<-ddply(backtest, .(numBrackets, percentile),mutate,
                winningYears=sum(Prize_same>0),
                CumProfit=cumsum(Prize_same)-cumsum(Entry))
test<-backtest[backtest$percentile==.9,]
groupedLine(test, title="Cumulative Profit, 90th-percentile parameter")

```


As you can see, optimization on 90th percentile still gave the best result, even in a large pool. But while the ROI is higher, the percentage of winning years starts to decrease. I repeat this again using 100-man pool scoring:

```{r fig3, echo=F, eval=T , include=T,fig.height = 3, fig.width = 5, fig.align = "center"}
percentile<-.99

backtest$numWinning<-rowSums(apply(backtest[, grepl("result", colnames(backtest))],2, function(x) x>=percentile  ), na.rm=T)
backtest$numSecond<-rowSums(apply(backtest[, grepl("result", colnames(backtest))],2, function(x) x<percentile & x>=percentile-(1-percentile) ), na.rm=T)
backtest$Prize<-(1/(1-percentile))*backtest$numWinning
backtest$Prize_same<-(1/(1-percentile))*(backtest$numWinning>=1)


means<-ddply(backtest, .(percentile, numBrackets), summarize,ROI=100*sum(Prize_same-Entry)/sum(Entry), seROI=100*sd((Prize_same-Entry)/Entry)/length(year))
means[, c("percentile", "numBrackets")]<-sapply(means[, c("percentile", "numBrackets")], as.factor)
makePlot(means, title="ROI, Large Pool Scoring")

backtest<-ddply(backtest, .(numBrackets, percentile),mutate,
                winningYears=sum(Prize_same>0),
                CumProfit=cumsum(Prize_same)-cumsum(Entry))
test<-backtest[backtest$percentile==.9,]
groupedLine(test, title="Cumulative Profit, 90th-percentile parameter")

```


90th percentile always does well. I'm not sure the reason for this but I'm guessing it has to do with sample size and that using 90% gives you brackets that have variance but are not overfit to your simulations. It could also just be that I am overfitting to the backtest, so doing things like testing sensitivity to different projection systems is something that would be worthwhile.

##Conclusion:

Overall, a system should give you good results and also have good median results. In finance, they have things like Sharpe ratio to measure the trade-off of risk and returns. However, just by looking at the plots, it seems the best thing to do is to **use .9 optimization percentile and to multi-enter. This is true regardless of your actual pool size. If you have a choice,it's best to enter small pools (<=20 people)**. With pools of this size you are giving yourself a really good shot of winning.Ideally, you have a lot of friends and can divide them into different groups without them knowing. That way you can put a different bracket in each group. Or, make a pool that allows for multi-entry. While the largest pools may give the most profit over time, it's better to enter smaller pools to reduce your risk of losing. All of this has been for 1-2-4-8-16-32 scoring. I also assume brackets cannot finish in the same place i.e. you are multi-entering the same pool. Because the optimized brackets are so uncorrelated this assumption doesn't really matter. In a future post I will examine different scoring systems in addition to testing sensitivity of this analysis to a different projections system. You can replicate my analysis by manually running the [app](https://bracketmath.shinyapps.io/ncaa/) or by downloading my code from [github](https://github.com/dlm1223/march-madness/tree/master/Backtest%20files).




